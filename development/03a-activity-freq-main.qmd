---
title: "02 CEJST Activity"
format: pdf
---

<!-- solution-begin -->
::: {.callout-note icon="false" title="Instructor Note: Introduction"}
These are instructor notes; they will be removed from the student-facing assignment file.

This is the **Frequentist** form of the activity. 
:::
<!-- solution-end -->
\newpage

Armed with all of that background knowledge on the CEJST dataset and on statistical inference, we can proceed with a detailed analysis of the data. In particular, we are interested in assessing the following hypothesis:

> *As the population of Black Americans increases (decreases), the level of energy expenditure increases (decreases).*

In this part of the session you will interpret results from a statistical model fitted to datasets from different U.S. States.

```{r setup}
#| include: false
#| echo: false
library(tidyverse)
library(broom)

filename <- "../data/1.0-communities.csv"
```

```{r wrangling}
#| include: false
#| echo: false
df_raw <- read_csv(filename)
df_data <- 
  df_raw %>%
  janitor::clean_names()
```

# Overview

Throughout this activity, you will be studying a statistical model fitted to data from the CEJST dataset. As a reminder, we are interested in the `Energy Burden Percentile` (higher values correspond to a higher burden) and the `Percent Black Census Tract` (which measures the number of people in a region who are Black).

```{r fig-overview}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
#| fig-cap: CEJST data for Massachusetts.
df_data %>% 
  filter(state_territory == "Massachusetts") %>% 
  
  ggplot(aes(
    percent_black_or_african_american_alone,
    energy_burden_percentile
  )) +
  geom_point(size = 0.1) +
  facet_wrap(~state_territory, ncol = 2) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    x = "Percent Black Census Tract",
    y = "Energy Burden Percentile",
  )
```

From this scatterplot, we can see that the energy burden seems to
increase as the percent Black increases. However, we can make this rough
observation more formal by using a statistical model.

# Analyze a Frequentist Model

To analyze the dataset, we will use the following statistical model,

$$ B = m P + b + \epsilon $$

where $B$ is the energy burden percentile, $P$ is the percent Black, $m$
is the slope parameter, $b$ is the intercept parameter, and $\epsilon$
is a *residual* term that represents factors not accounted in the model.
The residual term is assumed to be normally distributed
$\epsilon \sim N(0, \sigma^2)$ with an unknown parameter $\sigma^2$.

<!-- solution-begin -->

::: {.callout-note icon="false" title="Instructor Note: Model Assumptions"}
Note that this model makes a number of important assumptions, which
students may identify and question. We recommend validating student
input, but try to maintain a focus on the assumptions that are aligned
with the lesson's learning objectives. We enumerate important model
assumptions, ramifications, and relevance to learning objectives here:

-   The responses $B_i$ are independent when conditioned on the percent
    Black $P$.
    -   This is almost surely not true as there are a variety of other
        factors that affect one's energy burden, such as State-level
        economic policies. These other factors are not entirely captured
        in our lone predictor ($P$), which may manifest as association
        between the observed responses ($B_i$). This will lead to an
        *omitted variable bias* in our estimates.
    -   While omitted variable bias is an important consideration, it is
        outside the learning objectives in this lesson since this
        assumption is shared between the Frequentist and Bayesian
        approaches.
-   The structure of the response is linear; that is
    $B = m P + b + \epsilon$.
    -   This discounts the possibility of nonlinearity; for instance,
        there could be little change in the mean energy burden at small
        percent Black, but much larger change at higher values.
    -   While the structure of the response is an important
        consideration, it is outside the learning objectives in this
        lesson since this assumption is shared between the Frequentist
        and Bayesian approaches.
-   Residuals are normally distributed $\epsilon \sim N(0, \sigma^2)$
    with constant $\sigma^2$.
    -   This will never be exactly true, which we can check by
        inspecting the residuals. This assumptions has implications for
        our predictive uncertainty; for instance, assuming a constant
        $\sigma^2$ discounts the possibility of heteroskedasticity.
    -   While the residual distribution is an important consideration,
        it is outside the learning objectives in this lesson since this
        assumption is shared between the Frequentist and Bayesian
        approaches.
-   The intercept $b$ and slope $m$ parameters are treated as fixed but unknown constants.
    -   This is a fundamental component of the Frequentist approach, and
        hence is directly related to the lesson's learning objectives.
:::

<!-- solution-end -->

```{r fit-MA}
#| include: false
#| echo: false
#| cache: true
df_MA <- 
  df_data %>% 
  filter(
    str_detect(state_territory, "Massachusetts"),
    !is.na(percent_black_or_african_american_alone),
    !is.na(energy_burden_percentile)
  ) %>% 
  select(energy_burden_percentile, percent_black_or_african_american_alone)

model_MA <- 
  lm(
    data = df_MA,
    formula = energy_burden_percentile ~ percent_black_or_african_american_alone,
  )
```

## Study the MLE estimates

Results from a Frequentist model take the form of a *maximum likelihood estimates* for the model parameters. The model has two parameters that are closely related to our hypothesis: The slope $m$ and intercept $b$ of the fitted line. "Fitting" the Frequentist model to the Massachusetts dataset will result in point estimate ("best fit") values for the parameters and a *confidence interval* for each estimate. The point estimates and confidence intervals from fitting the Massachusetts data are shown below:

```{r mle-MA}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 8
df_model_MA <- 
  model_MA %>% 
  tidy() %>% 
  mutate(
    lower = estimate - 2 * std.error,
    upper = estimate + 2 * std.error,
  )

df_model_MA %>% 
  select(term, lower, estimate, upper) %>% 
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "percent_black_or_african_american_alone" ~ "Slope"
    )
  ) %>% 
  mutate(across(
    c(lower, estimate, upper),
    ~round(., digits = 1)
  )) %>% 
  
  select(Term = term, Lower = lower, Estimate = estimate, Upper = upper) %>% 
  knitr::kable()
```

A confidence interval helps us determine **how confident** we should be in conclusions drawn from the model. The next exercise will help you assess confidence in results based on the fitted model.

## Assessing confidence

Let's imagine three different posterior sets of point estimates and confidence intervals for the slope parameter $m$:

| **Case** | **Lower** | **Estimate** | **Upper** |
|----------|-----------|--------------|-----------|
|    A     |   -10     |      60      |    100    |
|    B     |    -5     |       5      |     15    |
|    C     |    25     |      50      |     75    |

The most important thing to remember about confidence intervals is the *golden rule*....

::: {.callout-note icon="false" title="Golden Rule for Confidence Intervals"}
When studying a confidence interval, we should assume the value we are trying to estimate could be **anywhere** inside the interval.
:::

**Model summaries**

<!-- task-begin -->

::: {.callout-note icon="false" title="Questions for the Class"}
-   Which case (A, B, or C) gives the *highest* point estimate?
    -   (Write your response here): 
-   Which cases (A, B, or C) include $0$ between their `Lower` and `Upper` values?
    -   (Write your response here): 
-   Which case (A, B, or C) has the *narrowest* confidence interval? (i.e., the difference between `Upper - Lower` is smallest)
    -   (Write your response here): 
-   Which case suggests the *highest confidence* that the slope parameter is positive? How can you tell?
    -   (Write your response here): 
<!-- task-end -->
<!-- solution-begin -->
-   Which case (A, B, or C) gives the *highest* point estimate?
    -   Case A
-   Which cases (A, B, or C) include $0$ between their `Lower` and `Upper` values?
    -   Cases A and B
-   Which case (A, B, or C) has the *narrowest* confidence interval? (i.e., the difference between `Upper - Lower` is smallest)
    -   Case B
-   Which case suggests the *highest confidence* that the slope parameter is positive? How can you tell?
    -   Case C; it is the only CI that excludes zero.
<!-- solution-end -->
:::

**General inference**

::: {.callout-note icon="false" title="Questions for the Class"}
-   How does the slope parameter relate to our hypothesis? As a reminder, our hypothesis is: 

> *As the population of Black Americans increases (decreases), the level of energy expenditure increases (decreases).* 

<!-- task-begin -->
    -   (Write your response here): 
<!-- task-end -->
<!-- solution-begin -->
    -   The slope parameter is directly related to our hypothesis. A positive slope is in agreement with our hypothesis.
<!-- solution-end -->
:::

Let's return to the posterior from our model for the Massachusetts data and use the same reasoning as above to make sense of the results.

```{r mle-MA-repeat}
#| warning: false
#| echo: false
#| fig-align: center
df_model_MA %>% 
  select(term, lower, estimate, upper) %>% 
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "percent_black_or_african_american_alone" ~ "Slope"
    )
  ) %>% 
  mutate(across(
    c(lower, estimate, upper),
    ~round(., digits = 1)
  )) %>% 
  
  select(Term = term, Lower = lower, Estimate = estimate, Upper = upper) %>% 
  knitr::kable()
```

::: {.callout-note icon="false" title="Questions for the Class"}
As a reminder, our hypothesis is:

> *As the population of Black Americans increases (decreases), the level of energy expenditure increases (decreases).*

<!-- task-begin -->
-   For Massachusetts, does the fitted model support or contradict our
    hypothesis? 
    -   (Write your response here):
-   How confident are you in the model results?
    -   (Write your response here): 
<!-- task-end -->
<!-- solution-begin -->
    -   The fitted model supports our hypothesis.
-   How confident are you in the model results?
    -   The confidence interval excludes zero, which suggests a high confidence in a positive slope. We can be confident at the level chosen; in our case 95%.
<!-- solution-end -->
:::

## Study the prediction and confidence band

Frequentist analysis produces a "best fit" line, but the confidence intervals on the slope and intercept imply a *family* of lines. We call this the *confidence band* for the regression line. For instance, the following visualizes the best fit line (solid blue) and confidence band (transparent blue) against the Massachusetts data. Practically, the confidence band tells us that any line we can draw within the bounds is *compatible* with the data we have.

```{r}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
#| fig-cap: Best fit line and confidence band for Massachusetts data.
df_MA_pred <-  
  tibble(percent_black_or_african_american_alone = seq(
    min(df_MA$percent_black_or_african_american_alone),
    max(df_MA$percent_black_or_african_american_alone),
    length.out = 100
  ))

df_MA_pred <- 
  bind_cols(
    df_MA_pred,
    predict(
      model_MA, 
      interval = 'confidence',
      newdata = df_MA_pred
    )
  )

df_MA_pred %>% 

  ggplot(aes(
    x = percent_black_or_african_american_alone,
  )) +
  geom_ribbon(
    aes(ymin = lwr, ymax = upr),
    fill = "blue",
    alpha = 1/3
  ) +
  geom_line(
    aes(y = fit),
    linewidth = 0.7,
    color = "blue"
  ) +
  geom_point(
    data = df_MA,
    mapping = aes(y = energy_burden_percentile),
    size = 0.1
  ) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    x = "Percent Black Census Tract",
    y = "Energy Burden Percentile",
  )
```

We can use this kind of plot (predictions against observed data) as a way to sanity check the model. You'll do this in the following questions.

::: {.callout-note icon="false" title="Questions for the Class"}
-   Do all data points (black dots) land near the best fit line (solid blue line), or do some dots land far from the line?
    -   (Write your response here):
-   This model represents the *overall trend* in the data well. In your own words, describe how the model fits the overall trend in the data.
    -   (Write your response here): 
<!-- solution-begin -->
-   Do all data points (black dots) land near the best fit line (solid blue line), or do some dots land far from the line?
    -   No, there is variability in the data that remains unexplained by the model.
-   This model represents the *overall trend* in the data well. In your own words, describe how the model fits the overall trend in the data.
    -   While the data points exhibit a great deal of variability, their average tends to increase from left to right. More formally, their mean conditional on the predictor tends to increase.
<!-- solution-end -->
:::

The model should fit the data reasonably well; otherwise, we should *distrust* its results. It doesn't matter if the MLE estimates agree with our hypothesis if the model fits the data poorly!

## Data rollout

For the rest of the activity we'll consider a scenario where our access to the CEJST data is limited: Suppose we are conducting our analysis while the data are actively being gathered. In this case, we may have access to the data for some states before others. In this context, this means we'll study some of the individual states before we study the full USA.

Armed with this fundamental understanding of statistical inference, we can now apply these ideas to study data from the other states!

\newpage
# Colorado

```{r fit-CO}
#| include: false
#| echo: false
#| cache: true
df_CO <- 
  df_data %>% 
  filter(
    str_detect(state_territory, "Colorado"),
    !is.na(percent_black_or_african_american_alone),
    !is.na(energy_burden_percentile)
  ) %>% 
  select(energy_burden_percentile, percent_black_or_african_american_alone)

model_CO <- 
  lm(
    data = df_CO,
    formula = energy_burden_percentile ~ percent_black_or_african_american_alone,
  )
```

## Study the results

```{r mle-CO}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 8
df_model_CO <- 
  model_CO %>% 
  tidy() %>% 
  mutate(
    lower = estimate - 2 * std.error,
    upper = estimate + 2 * std.error,
  )

df_model_CO %>% 
  select(term, lower, estimate, upper) %>% 
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "percent_black_or_african_american_alone" ~ "Slope"
    )
  ) %>% 
  mutate(across(
    c(lower, estimate, upper),
    ~round(., digits = 1)
  )) %>% 
  
  select(Term = term, Lower = lower, Estimate = estimate, Upper = upper) %>% 
  knitr::kable()
```




```{r}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
#| fig-cap: Best fit line and confidence band for Colorado data.

df_CO_pred <-  
  tibble(percent_black_or_african_american_alone = seq(
    min(df_CO$percent_black_or_african_american_alone),
    max(df_CO$percent_black_or_african_american_alone),
    length.out = 100
  ))

df_CO_pred <- 
  bind_cols(
    df_CO_pred,
    predict(
      model_CO, 
      interval = 'confidence',
      newdata = df_CO_pred
    )
  )

df_CO_pred %>% 

  ggplot(aes(
    x = percent_black_or_african_american_alone,
  )) +
  geom_ribbon(
    aes(ymin = lwr, ymax = upr),
    fill = "blue",
    alpha = 1/3
  ) +
  geom_line(
    aes(y = fit),
    linewidth = 0.7,
    color = "blue"
  ) +
  geom_point(
    data = df_CO,
    mapping = aes(y = energy_burden_percentile),
    size = 0.1
  ) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    x = "Percent Black Census Tract",
    y = "Energy Burden Percentile",
  )
```

::: {.callout-note icon="false" title="Studying Model Results"}
<!-- task-begin -->
-   What does the model suggest about the trend of energy burden with percent Black in Colorado?
    -   (Write your response here):
-   How well do the model predictions match the data?
    -   (Write your response here):
-   How confident are you in your conclusion?
    -   (Write your response here): 
<!-- task-end -->
<!-- solution-begin -->
-   What does the model suggest about the trend of energy burden with percent Black in Colorado?
    -   The model gives a negative MLE for the slope, but the CI includes zero.
-   How well do the model predictions match the data?
    -   There is much scatter around the line, but there does seem to be an overall trend downwards.
-   How confident are you in your conclusion?
    -   Not very confident, as the slope CI includes zero.
<!-- solution-end -->
:::

# Florida

In some cases, we may find that gathering more data is simply not possible. Let's suppose that, for some reason, Florida is unwilling to provide all of their energy burden data. Therefore, we must figure out what to do with only $n=25$ observations:

```{r}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
#| fig-cap: Limited data for Florida.
set.seed(103)

df_FL <- 
  df_data %>% 
  filter(state_territory == "Florida") %>% 
  slice_sample(n = 25)

df_FL %>% 
  ggplot(aes(
    percent_black_or_african_american_alone,
    energy_burden_percentile
  )) +
  geom_point(size = 1.0) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    x = "Percent Black Census Tract",
    y = "Energy Burden Percentile",
  )
```

Given the limited data, we'd expect more uncertainty in our estimates. This will be reflected as a wider confidence interval.

\newpage
## Study the results

```{r fit-FL}
#| include: false
#| echo: false
#| cache: true
model_FL <- 
  lm(
    data = df_FL,
    formula = energy_burden_percentile ~ percent_black_or_african_american_alone,
  )
```


```{r mle-FL}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
df_model_FL <- 
  model_FL %>% 
  tidy() %>% 
  mutate(
    lower = estimate - 2 * std.error,
    upper = estimate + 2 * std.error,
  )

df_model_FL %>% 
  select(term, lower, estimate, upper) %>% 
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "percent_black_or_african_american_alone" ~ "Slope"
    )
  ) %>% 
  mutate(across(
    c(lower, estimate, upper),
    ~round(., digits = 1)
  )) %>% 
  
  select(Term = term, Lower = lower, Estimate = estimate, Upper = upper) %>% 
  knitr::kable()
```



```{r}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
#| fig-cap: Best fit line and confidence band for Florida data.

df_FL_pred <-  
  tibble(percent_black_or_african_american_alone = seq(
    min(df_FL$percent_black_or_african_american_alone),
    max(df_FL$percent_black_or_african_american_alone),
    length.out = 100
  ))

df_FL_pred <- 
  bind_cols(
    df_FL_pred,
    predict(
      model_FL, 
      interval = 'confidence',
      newdata = df_FL_pred
    )
  )

df_FL_pred %>% 

  ggplot(aes(
    x = percent_black_or_african_american_alone,
  )) +
  geom_ribbon(
    aes(ymin = lwr, ymax = upr),
    fill = "blue",
    alpha = 1/3
  ) +
  geom_line(
    aes(y = fit),
    linewidth = 0.7,
    color = "blue"
  ) +
  geom_point(
    data = df_FL,
    mapping = aes(y = energy_burden_percentile),
    size = 1.0
  ) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    x = "Percent Black Census Tract",
    y = "Energy Burden Percentile",
  )
```

::: {.callout-note icon="false" title="Studying Model Results"}
<!-- task-begin -->
-   What does the model suggest about the trend of energy burden with percent Black in Florida?
    -   (Write your response here):
-   How well do the model predictions match the data?
    -   (Write your response here):
-   How confident are you in your conclusion?
    -   (Write your response here): 
<!-- task-end -->
<!-- solution-begin -->
-   What does the model suggest about the trend of energy burden with percent Black in Colorado?
    -   The model gives a positive MLE for the slope, but the CI is wide and includes zero.
-   How well do the model predictions match the data?
    -   There is much scatter around the line, but there does seem to be an overall trend downwards.
-   How confident are you in your conclusion?
    -   Not very confident, as the slope CI includes zero.
<!-- solution-end -->
:::

\clearpage
# Full USA

After waiting some time, we finally get access to the full U.S. CEJST dataset.

```{r}
#| include: false
#| echo: false
#| cache: true
# Random sample of valid observations
df_USA <- 
  df_data %>% 
  filter(!is.na(percent_black_or_african_american_alone)) %>% 
  slice_sample(n = 10000)
```

## Study the results

```{r fit-USA}
#| include: false
#| echo: false
#| cache: true
model_USA <- 
  lm(
    data = df_USA,
    formula = energy_burden_percentile ~ percent_black_or_african_american_alone,
  )
```


```{r mle-USA}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 8
df_model_USA <- 
  model_USA %>% 
  tidy() %>% 
  mutate(
    lower = estimate - 2 * std.error,
    upper = estimate + 2 * std.error,
  )

df_model_USA %>% 
  select(term, lower, estimate, upper) %>% 
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "percent_black_or_african_american_alone" ~ "Slope"
    )
  ) %>% 
  mutate(across(
    c(lower, estimate, upper),
    ~round(., digits = 1)
  )) %>% 
  
  select(Term = term, Lower = lower, Estimate = estimate, Upper = upper) %>% 
  knitr::kable()
```



```{r}
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 3
#| fig-cap: Best fit line and confidence band for full USA data.

df_USA_pred <-  
  tibble(percent_black_or_african_american_alone = seq(
    min(df_USA$percent_black_or_african_american_alone),
    max(df_USA$percent_black_or_african_american_alone),
    length.out = 100
  ))

df_USA_pred <- 
  bind_cols(
    df_USA_pred,
    predict(
      model_USA, 
      interval = 'confidence',
      newdata = df_USA_pred
    )
  )

df_USA_pred %>% 

  ggplot(aes(
    x = percent_black_or_african_american_alone,
  )) +
  geom_ribbon(
    aes(ymin = lwr, ymax = upr),
    fill = "blue",
    alpha = 1/3
  ) +
  geom_line(
    aes(y = fit),
    linewidth = 0.7,
    color = "blue"
  ) +
  geom_point(
    data = df_USA,
    mapping = aes(y = energy_burden_percentile),
    size = 1.0
  ) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    x = "Percent Black Census Tract",
    y = "Energy Burden Percentile",
  )
```

::: {.callout-note icon="false" title="Studying Model Results"}
<!-- task-begin -->
-   What does the model suggest about the trend of energy burden with percent Black in the full USA?
    -   (Write your response here):
-   How well do the model predictions match the data?
    -   (Write your response here):
-   How confident are you in your conclusion?
    -   (Write your response here): 
<!-- task-end -->
<!-- solution-begin -->
-   What does the model suggest about the trend of energy burden with percent Black in the full USA?
    -   The model gives a positive MLE for the slope, the CI is narrow and excludes zero.
-   How well do the model predictions match the data?
    -   There is considerable scatter around the trend, much more than what we've seen before. However, there does appear to be a clear upward trend.
-   How confident are you in your conclusion?
    -   Quite confident, as the slope CI excludes zero.
<!-- solution-end -->
:::

**Coming up next**: When the instructor tells you, please start working through `04 Activity Wrap-up` with the other students at your table. **Please do not move on until your instructor tells you to.**

\newpage
(This page intentionally left blank)
